{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis:\n",
      "This joke relies on a pun, playing on the similar sounds of \"fish and ships\" and \"fish and chips.\" The humor comes from the unexpected twist in the punchline, where the listener is led to believe the pirate is interested in the seafood, but it turns out he is actually interested in the ships.\n",
      "\n",
      "Critique:\n",
      "- The joke is clever and plays on the common stereotype of pirates being interested in ships.\n",
      "- The wordplay is effective and adds an element of surprise to the punchline.\n",
      "- The joke is simple and easy to understand, making it accessible to a wide audience.\n",
      "- However, the joke may be considered somewhat predictable or clichÃ©, as puns involving pirates and ships are quite common.\n",
      "- Some may find the humor to be a bit corny or cheesy, as pun-based jokes can sometimes come across as forced or contrived.\n",
      "- Overall, while the joke is amusing and may elicit a chuckle from some, it may not be considered particularly original or groundbreaking in terms of comedy.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "\n",
    "# `pip install llama-index-llms-openai` if you don't already have it\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "class JokeEvent(Event):\n",
    "    joke: str\n",
    "\n",
    "\n",
    "class JokeFlow(Workflow):\n",
    "    llm = OpenAI()\n",
    "\n",
    "    @step\n",
    "    async def generate_joke(self, ev: StartEvent) -> JokeEvent:\n",
    "        topic = ev.topic\n",
    "\n",
    "        prompt = f\"Write your best joke about {topic}.\"\n",
    "        response = await self.llm.acomplete(prompt)\n",
    "        return JokeEvent(joke=str(response))\n",
    "\n",
    "    @step\n",
    "    async def critique_joke(self, ev: JokeEvent) -> StopEvent:\n",
    "        joke = ev.joke\n",
    "\n",
    "        prompt = f\"Give a thorough analysis and critique of the following joke: {joke}\"\n",
    "        response = await self.llm.acomplete(prompt)\n",
    "        return StopEvent(result=str(response))\n",
    "\n",
    "\n",
    "w = JokeFlow(timeout=60, verbose=False)\n",
    "result = await w.run(topic=\"pirates\")\n",
    "print(str(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
